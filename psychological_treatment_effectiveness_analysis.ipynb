{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avivs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import fastText\n",
    "import nltk\n",
    "import gensim\n",
    "import json\n",
    "import gzip\n",
    "import io\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "      <th>Noun</th>\n",
       "      <th>1st Body</th>\n",
       "      <th>ConciousWord</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Past</th>\n",
       "      <th>Present</th>\n",
       "      <th>Future</th>\n",
       "      <th>Other</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Adverb</th>\n",
       "      <th>Infinitive</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>conciousword</td>\n",
       "      <td>2409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pst1fst</td>\n",
       "      <td>1765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>לא</td>\n",
       "      <td>1604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>זה</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>אני</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  freq  Noun  1st Body  ConciousWord  Verb  Past  Present  \\\n",
       "0  conciousword  2409     0         0             0     0     0        0   \n",
       "1       pst1fst  1765     0         0             0     0     0        0   \n",
       "2            לא  1604     0         0             0     0     0        0   \n",
       "3            זה  1050     0         0             0     0     0        0   \n",
       "4           אני   987     0         1             0     0     0        0   \n",
       "\n",
       "   Future  Other  Adjective  Adverb  Infinitive  Emotion  Name  \n",
       "0       0      0          0       0           0        0     0  \n",
       "1       0      0          0       0           0        0     0  \n",
       "2       0      1          0       0           0        0     0  \n",
       "3       0      1          0       0           0        0     0  \n",
       "4       0      0          0       0           0        0     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_excel(\"words.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[A-Za-z]+\")\n",
    "english_words =[]\n",
    "\n",
    "for word in df['word']:\n",
    "    if pattern.fullmatch(word):\n",
    "        english_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conciousword',\n",
       " 'spectoken',\n",
       " 'break',\n",
       " 'laugh',\n",
       " 'unclear',\n",
       " 'ct',\n",
       " 'shit',\n",
       " 'happens',\n",
       " 'alert',\n",
       " 'doing',\n",
       " 'there',\n",
       " 'jobs',\n",
       " 'ups',\n",
       " 'and',\n",
       " 'downs',\n",
       " 'out',\n",
       " 'cool',\n",
       " 'mri',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'place']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We seperate the tagged words to groups\n",
    "from collections import defaultdict\n",
    "groups = defaultdict(list)\n",
    "    \n",
    "for i,word in enumerate(df[\"word\"]):\n",
    "    for c in range(2,(len(df.columns)),1):\n",
    "        if df[df.columns[c]][i] == 1:\n",
    "            groups[df.columns[c]].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Other', '1st Body', 'Verb', 'Past', 'Adverb', 'Noun', 'ConciousWord', 'Present', 'Adjective', 'Name', 'Emotion', 'Infinitive', 'Future'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all files of patients before treatment\n",
    "beforeArr = []\n",
    "for index in range(1, 21):\n",
    "    name = \"{index}.txt\".format(index=index)\n",
    "    path = os.path.join('before/', name)\n",
    "    with io.open(path, mode=\"r\", encoding=\"utf-8\") as fd:\n",
    "        content = fd.read()\n",
    "        content = re.sub(r'\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}', 'date', content)\n",
    "        beforeArr.append(content.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all files of patients after treatment\n",
    "afterArr = []\n",
    "for index in range(1, 21):\n",
    "    name = \"{index}.txt\".format(index=index)\n",
    "    path = os.path.join('after/', name)\n",
    "    with io.open(path, mode=\"r\", encoding=\"utf-8\") as fd:\n",
    "        content = fd.read()\n",
    "        content = re.sub(r'\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}', 'date', content)\n",
    "        afterArr.append(content.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'freq', 'Noun', '1st Body', 'ConciousWord', 'Verb', 'Past',\n",
       "       'Present', 'Future', 'Other', 'Adjective', 'Adverb', 'Infinitive',\n",
       "       'Emotion', 'Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients dataframe <br>- including the ratio between before and after treatment for each group and patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Noun Before</th>\n",
       "      <th>1st Body Before</th>\n",
       "      <th>ConciousWord Before</th>\n",
       "      <th>Verb Before</th>\n",
       "      <th>Past Before</th>\n",
       "      <th>Present Before</th>\n",
       "      <th>Future Before</th>\n",
       "      <th>Other Before</th>\n",
       "      <th>Adjective Before</th>\n",
       "      <th>...</th>\n",
       "      <th>Verb Ratio</th>\n",
       "      <th>Past Ratio</th>\n",
       "      <th>Present Ratio</th>\n",
       "      <th>Future Ratio</th>\n",
       "      <th>Other Ratio</th>\n",
       "      <th>Adjective Ratio</th>\n",
       "      <th>Adverb Ratio</th>\n",
       "      <th>Infinitive Ratio</th>\n",
       "      <th>Emotion Ratio</th>\n",
       "      <th>Name Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.991</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.341</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.131</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.107</td>\n",
       "      <td>3.333</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.152</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.511</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.839</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.632</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient  Noun Before  1st Body Before  ConciousWord Before  Verb Before  \\\n",
       "0        0        0.225            0.077                0.031        0.187   \n",
       "1        1        0.217            0.114                0.010        0.189   \n",
       "2        2        0.156            0.096                0.001        0.186   \n",
       "3        3        0.168            0.091                0.008        0.171   \n",
       "4        4        0.242            0.094                0.015        0.156   \n",
       "\n",
       "   Past Before  Present Before  Future Before  Other Before  Adjective Before  \\\n",
       "0        0.112           0.075          0.000         0.311             0.059   \n",
       "1        0.100           0.071          0.018         0.243             0.044   \n",
       "2        0.131           0.050          0.014         0.279             0.036   \n",
       "3        0.104           0.053          0.014         0.281             0.068   \n",
       "4        0.099           0.044          0.013         0.252             0.068   \n",
       "\n",
       "   ...  Verb Ratio  Past Ratio  Present Ratio  Future Ratio  Other Ratio  \\\n",
       "0  ...       1.191       0.991          2.206         0.000        1.280   \n",
       "1  ...       1.005       1.010          1.000         1.000        0.946   \n",
       "2  ...       0.903       0.766          1.429         1.750        1.187   \n",
       "3  ...       1.082       1.010          1.152         1.400        1.115   \n",
       "4  ...       1.020       0.971          0.863         1.182        0.920   \n",
       "\n",
       "   Adjective Ratio  Adverb Ratio  Infinitive Ratio  Emotion Ratio  Name Ratio  \n",
       "0            1.341         0.778             0.906          1.625       0.667  \n",
       "1            0.978         1.131             0.857          0.800       1.000  \n",
       "2            1.800         1.109             1.107          3.333       0.300  \n",
       "3            1.511         0.918             0.839          2.500       1.125  \n",
       "4            1.333         0.861             1.632          0.778       1.800  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientsdf= pd.read_excel(\"before_and_after.xlsx\")\n",
    "if \"Unnamed: 0\" in patientsdf.columns:\n",
    "    patientsdf = patientsdf.drop(columns=\"Unnamed: 0\")\n",
    "patientsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RatioEachGroupInFile(file):\n",
    "    \n",
    "    file_groups = {}\n",
    "    \n",
    "    for key,val in groups.items():\n",
    "         file_groups[key] = float( '%.3f' % ( sum([sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), file)) for word in val]) / len(file.split()) ) )\n",
    "   \n",
    "    return file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Noun Before', '1st Body Before', 'ConciousWord Before', 'Verb Before',\n",
       "       'Past Before', 'Present Before', 'Future Before', 'Other Before',\n",
       "       'Adjective Before', 'Adverb Before', 'Infinitive Before',\n",
       "       'Emotion Before', 'Name Before'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientsdf.columns[1:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of words from each group in files before treatment\n",
    "\n",
    "for i_patient,file in enumerate(beforeArr):\n",
    "    \n",
    "    ratio_each_group_in_file= RatioEachGroupInFile(file)\n",
    "    for col in patientsdf.columns[1:14]:\n",
    "        key= col.split()\n",
    "        key = \" \".join(key[0:-1])\n",
    "        patientsdf.loc[i_patient, col] = ratio_each_group_in_file.get(key,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of words from each group in files after treatment\n",
    "\n",
    "for i_patient,file in enumerate(afterArr):\n",
    "    \n",
    "    ratio_each_group_in_file= RatioEachGroupInFile(file)\n",
    "    for col in patientsdf.columns[14:27]:\n",
    "        key= col.split()\n",
    "        key = \" \".join(key[0:-1])\n",
    "        patientsdf.loc[i_patient, col] = ratio_each_group_in_file.get(key,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Value_Ratio(a,b):\n",
    "    if b==0:\n",
    "        return None\n",
    "    return float('%.3f' % (a/b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ratio of words from each group before and after treatment for each patient\n",
    "for i_patient in range(0,len(afterArr)):\n",
    "   \n",
    "    for col in patientsdf.columns[27:40]:\n",
    "        key= col.split()\n",
    "        key = \" \".join(key[0:-1])\n",
    "        patientsdf.loc[i_patient, col] = Value_Ratio(patientsdf[key+' '+'Before'][i_patient],patientsdf[key+' '+'After'][i_patient])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Noun Before</th>\n",
       "      <th>1st Body Before</th>\n",
       "      <th>ConciousWord Before</th>\n",
       "      <th>Verb Before</th>\n",
       "      <th>Past Before</th>\n",
       "      <th>Present Before</th>\n",
       "      <th>Future Before</th>\n",
       "      <th>Other Before</th>\n",
       "      <th>Adjective Before</th>\n",
       "      <th>...</th>\n",
       "      <th>Verb Ratio</th>\n",
       "      <th>Past Ratio</th>\n",
       "      <th>Present Ratio</th>\n",
       "      <th>Future Ratio</th>\n",
       "      <th>Other Ratio</th>\n",
       "      <th>Adjective Ratio</th>\n",
       "      <th>Adverb Ratio</th>\n",
       "      <th>Infinitive Ratio</th>\n",
       "      <th>Emotion Ratio</th>\n",
       "      <th>Name Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.991</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.341</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.131</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.107</td>\n",
       "      <td>3.333</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.152</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.511</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.839</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.632</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient  Noun Before  1st Body Before  ConciousWord Before  Verb Before  \\\n",
       "0        0        0.225            0.077                0.031        0.187   \n",
       "1        1        0.217            0.114                0.010        0.189   \n",
       "2        2        0.156            0.096                0.001        0.186   \n",
       "3        3        0.168            0.091                0.008        0.171   \n",
       "4        4        0.242            0.094                0.015        0.156   \n",
       "\n",
       "   Past Before  Present Before  Future Before  Other Before  Adjective Before  \\\n",
       "0        0.112           0.075          0.000         0.311             0.059   \n",
       "1        0.100           0.071          0.018         0.243             0.044   \n",
       "2        0.131           0.050          0.014         0.279             0.036   \n",
       "3        0.104           0.053          0.014         0.281             0.068   \n",
       "4        0.099           0.044          0.013         0.252             0.068   \n",
       "\n",
       "   ...  Verb Ratio  Past Ratio  Present Ratio  Future Ratio  Other Ratio  \\\n",
       "0  ...       1.191       0.991          2.206         0.000        1.280   \n",
       "1  ...       1.005       1.010          1.000         1.000        0.946   \n",
       "2  ...       0.903       0.766          1.429         1.750        1.187   \n",
       "3  ...       1.082       1.010          1.152         1.400        1.115   \n",
       "4  ...       1.020       0.971          0.863         1.182        0.920   \n",
       "\n",
       "   Adjective Ratio  Adverb Ratio  Infinitive Ratio  Emotion Ratio  Name Ratio  \n",
       "0            1.341         0.778             0.906          1.625       0.667  \n",
       "1            0.978         1.131             0.857          0.800       1.000  \n",
       "2            1.800         1.109             1.107          3.333       0.300  \n",
       "3            1.511         0.918             0.839          2.500       1.125  \n",
       "4            1.333         0.861             1.632          0.778       1.800  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some words before,some words after, and ratio between them - for each patient\n",
    "patientsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsdf.to_excel(\"before_and_after.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average group  <br>- the prevalence of each group in the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_total= patientsdf.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Total Before</th>\n",
       "      <th>Total After</th>\n",
       "      <th>Total Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Future</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adjective</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.049</td>\n",
       "      <td>1.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Present</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Verb</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infinitive</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st Body</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Past</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.127</td>\n",
       "      <td>1.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adverb</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.091</td>\n",
       "      <td>1.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Noun</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Emotion</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ConciousWord</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Group Total Before Total After Total Ratio\n",
       "0         Future        0.014       0.012       1.167\n",
       "1      Adjective        0.053       0.049       1.082\n",
       "2        Present        0.051       0.048       1.062\n",
       "3           Verb        0.191       0.183       1.044\n",
       "4     Infinitive        0.027       0.026       1.038\n",
       "5       1st Body         0.11       0.107       1.028\n",
       "6           Past        0.129       0.127       1.016\n",
       "7         Adverb        0.092       0.091       1.011\n",
       "8          Other        0.261       0.264       0.989\n",
       "9           Noun        0.206       0.212       0.972\n",
       "10       Emotion         0.01       0.011       0.909\n",
       "11          Name        0.011       0.015       0.733\n",
       "12  ConciousWord        0.007       0.011       0.636"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The ratio between before and after treatment for each group .\n",
    "\n",
    "result=[]\n",
    "for i,group in enumerate(df.columns[2:]):\n",
    "    total_before = float( '%.3f' %(columns_total[i+1]/len(beforeArr) )) \n",
    "    total_after = float( '%.3f' %(columns_total[i+1+13]/len(afterArr) ))\n",
    "    result.append(tuple([group, total_before, total_after, float( '%.3f' %(total_before/total_after))]))\n",
    "\n",
    "total_ratio_df = pd.DataFrame(columns=[\"Group\",\"Total Before\",\"Total After\",\"Total Ratio\"],index=[i for i in range(len(groups.keys()))])\n",
    "for i,ratio in enumerate(sorted([tup[3] for tup in result],reverse=True)):\n",
    "    total_ratio_df.iloc[i] = [tup for tup in result if tup[3] == ratio][0]\n",
    "            \n",
    "total_ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We conclude that the use of conciousWords, emotion and names is higher in patients after treatment. On the other hand, pre-treatment patients are more likely to speak in future tense, and use adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paired sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun \n",
      "\t Ttest_relResult(statistic=-0.8876963278339951, pvalue=0.3858037998547559) \n",
      "\n",
      "\n",
      "\n",
      "1st Body \n",
      "\t Ttest_relResult(statistic=0.7920084838546424, pvalue=0.43813290594679144) \n",
      "\n",
      "\n",
      "\n",
      "We are rejecting null hypothesis of group:\t ConciousWord \n",
      "\n",
      "\n",
      "\n",
      "Verb \n",
      "\t Ttest_relResult(statistic=1.5415794517785657, pvalue=0.13966659337986873) \n",
      "\n",
      "\n",
      "\n",
      "Past \n",
      "\t Ttest_relResult(statistic=0.258116911523396, pvalue=0.7990918993466652) \n",
      "\n",
      "\n",
      "\n",
      "Present \n",
      "\t Ttest_relResult(statistic=0.6557294634948352, pvalue=0.5198602346450306) \n",
      "\n",
      "\n",
      "\n",
      "Future \n",
      "\t Ttest_relResult(statistic=1.1727468271726136, pvalue=0.25539145671537483) \n",
      "\n",
      "\n",
      "\n",
      "Other \n",
      "\t Ttest_relResult(statistic=-0.2961513538363088, pvalue=0.7703271684274191) \n",
      "\n",
      "\n",
      "\n",
      "Adjective \n",
      "\t Ttest_relResult(statistic=1.938970737913724, pvalue=0.06750299921741798) \n",
      "\n",
      "\n",
      "\n",
      "Adverb \n",
      "\t Ttest_relResult(statistic=0.5218254906039456, pvalue=0.607822179327818) \n",
      "\n",
      "\n",
      "\n",
      "Infinitive \n",
      "\t Ttest_relResult(statistic=0.6091773445145865, pvalue=0.5496224302863619) \n",
      "\n",
      "\n",
      "\n",
      "Emotion \n",
      "\t Ttest_relResult(statistic=-0.7542921084101732, pvalue=0.4599210858600682) \n",
      "\n",
      "\n",
      "\n",
      "Name \n",
      "\t Ttest_relResult(statistic=-1.828692357753088, pvalue=0.08318843139889721) \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "for col in df.columns[2:]:\n",
    "    ttest_pair = ttest_rel(patientsdf[col+\" Before\"], patientsdf[col+\" After\"])\n",
    "    if ttest_pair[1] > 0.05:\n",
    "        print(col,\"\\n\\t\",ttest_pair,\"\\n\\n\\n\")\n",
    "    else:\n",
    "        print(\"We are rejecting null hypothesis of group:\\t\",col,\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances dataframe  <br>- including the distance between each word to each group by using fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "m = FastText.load_fasttext_format(\"wiki.he\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemd\n",
    "from pyemd import emd\n",
    "from gensim.similarities import WmdSimilarity\n",
    "m.init_sims(replace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RowInformation(word):\n",
    "    dist_each_group_from_w = []\n",
    "    test_group = []\n",
    "    for col in df.columns[2:]:\n",
    "        val = groups[col]\n",
    "        if word in val:\n",
    "            test_group.append(col)\n",
    "            val.remove(word)\n",
    "        dist_each_group_from_w.append(tuple([col,m.wmdistance([word],val)]))\n",
    "    \n",
    "    #dist from each group\n",
    "    info_result = [tup[1] for tup in dist_each_group_from_w]\n",
    "    min_dist = min(info_result) #The smaller the distance, the similarity is higher \n",
    "    \n",
    "    #The word being tested\n",
    "    info_result.insert(0,word)\n",
    "    \n",
    "    #The appropriate groups\n",
    "    info_result.append(test_group)\n",
    "    \n",
    "    #The pred group\n",
    "    pred_group= [tup[0] for tup in dist_each_group_from_w if tup[1]==min_dist]\n",
    "    info_result.append(pred_group)\n",
    "    \n",
    "    return  info_result #All information for this word, we will add row to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df= pd.DataFrame(columns=['word','Noun-dist','1st Body-dist','ConciousWord-dist', 'Verb-dist', 'Past-dist',\n",
    "       'Present-dist', 'Future-dist', 'Other-dist', 'Adjective-dist', 'Adverb-dist', 'Infinitive-dist',\n",
    "       'Emotion-dist', 'Name-dist', 'test group', 'pred group'], index=df.index)\n",
    "\n",
    "for i,word in enumerate(df['word']):\n",
    "    dist_df.iloc[i] = RowInformation(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df.to_excel(\"distWord.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Noun-dist</th>\n",
       "      <th>1st Body-dist</th>\n",
       "      <th>ConciousWord-dist</th>\n",
       "      <th>Verb-dist</th>\n",
       "      <th>Past-dist</th>\n",
       "      <th>Present-dist</th>\n",
       "      <th>Future-dist</th>\n",
       "      <th>Other-dist</th>\n",
       "      <th>Adjective-dist</th>\n",
       "      <th>Adverb-dist</th>\n",
       "      <th>Infinitive-dist</th>\n",
       "      <th>Emotion-dist</th>\n",
       "      <th>Name-dist</th>\n",
       "      <th>test group</th>\n",
       "      <th>pred group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conciousword</td>\n",
       "      <td>1.024726</td>\n",
       "      <td>0.865388</td>\n",
       "      <td>1.023177</td>\n",
       "      <td>0.977810</td>\n",
       "      <td>0.956016</td>\n",
       "      <td>1.024793</td>\n",
       "      <td>0.983729</td>\n",
       "      <td>1.015281</td>\n",
       "      <td>1.028040</td>\n",
       "      <td>1.052661</td>\n",
       "      <td>1.029529</td>\n",
       "      <td>0.992928</td>\n",
       "      <td>1.020889</td>\n",
       "      <td>[]</td>\n",
       "      <td>['1st Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pst1fst</td>\n",
       "      <td>1.080852</td>\n",
       "      <td>0.947519</td>\n",
       "      <td>1.075936</td>\n",
       "      <td>1.041244</td>\n",
       "      <td>1.023871</td>\n",
       "      <td>1.081393</td>\n",
       "      <td>1.043694</td>\n",
       "      <td>1.068862</td>\n",
       "      <td>1.079621</td>\n",
       "      <td>1.104395</td>\n",
       "      <td>1.093289</td>\n",
       "      <td>1.052314</td>\n",
       "      <td>1.072672</td>\n",
       "      <td>[]</td>\n",
       "      <td>['1st Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>לא</td>\n",
       "      <td>1.396352</td>\n",
       "      <td>1.321483</td>\n",
       "      <td>1.394261</td>\n",
       "      <td>1.369859</td>\n",
       "      <td>1.358517</td>\n",
       "      <td>1.402034</td>\n",
       "      <td>1.365966</td>\n",
       "      <td>1.385281</td>\n",
       "      <td>1.404303</td>\n",
       "      <td>1.401154</td>\n",
       "      <td>1.360363</td>\n",
       "      <td>1.385373</td>\n",
       "      <td>1.393803</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['1st Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>זה</td>\n",
       "      <td>1.427666</td>\n",
       "      <td>1.335957</td>\n",
       "      <td>1.404164</td>\n",
       "      <td>1.394427</td>\n",
       "      <td>1.380367</td>\n",
       "      <td>1.434026</td>\n",
       "      <td>1.389433</td>\n",
       "      <td>1.403926</td>\n",
       "      <td>1.432238</td>\n",
       "      <td>1.432984</td>\n",
       "      <td>1.438741</td>\n",
       "      <td>1.405028</td>\n",
       "      <td>1.415064</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['1st Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>אני</td>\n",
       "      <td>1.391325</td>\n",
       "      <td>1.282952</td>\n",
       "      <td>1.369920</td>\n",
       "      <td>1.356715</td>\n",
       "      <td>1.347696</td>\n",
       "      <td>1.388988</td>\n",
       "      <td>1.345906</td>\n",
       "      <td>1.367902</td>\n",
       "      <td>1.383332</td>\n",
       "      <td>1.395155</td>\n",
       "      <td>1.412552</td>\n",
       "      <td>1.358124</td>\n",
       "      <td>1.376109</td>\n",
       "      <td>['1st Body']</td>\n",
       "      <td>['1st Body']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Noun-dist  1st Body-dist  ConciousWord-dist  Verb-dist  \\\n",
       "0  conciousword   1.024726       0.865388           1.023177   0.977810   \n",
       "1       pst1fst   1.080852       0.947519           1.075936   1.041244   \n",
       "2            לא   1.396352       1.321483           1.394261   1.369859   \n",
       "3            זה   1.427666       1.335957           1.404164   1.394427   \n",
       "4           אני   1.391325       1.282952           1.369920   1.356715   \n",
       "\n",
       "   Past-dist  Present-dist  Future-dist  Other-dist  Adjective-dist  \\\n",
       "0   0.956016      1.024793     0.983729    1.015281        1.028040   \n",
       "1   1.023871      1.081393     1.043694    1.068862        1.079621   \n",
       "2   1.358517      1.402034     1.365966    1.385281        1.404303   \n",
       "3   1.380367      1.434026     1.389433    1.403926        1.432238   \n",
       "4   1.347696      1.388988     1.345906    1.367902        1.383332   \n",
       "\n",
       "   Adverb-dist  Infinitive-dist  Emotion-dist  Name-dist    test group  \\\n",
       "0     1.052661         1.029529      0.992928   1.020889            []   \n",
       "1     1.104395         1.093289      1.052314   1.072672            []   \n",
       "2     1.401154         1.360363      1.385373   1.393803     ['Other']   \n",
       "3     1.432984         1.438741      1.405028   1.415064     ['Other']   \n",
       "4     1.395155         1.412552      1.358124   1.376109  ['1st Body']   \n",
       "\n",
       "     pred group  \n",
       "0  ['1st Body']  \n",
       "1  ['1st Body']  \n",
       "2  ['1st Body']  \n",
       "3  ['1st Body']  \n",
       "4  ['1st Body']  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "dist_df = pd.read_excel(\"distWord.xlsx\")\n",
    "if \"Unnamed: 0\" in dist_df.columns:\n",
    "    dist_df = dist_df.drop(columns=\"Unnamed: 0\")\n",
    "dist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.09767092411720511\n"
     ]
    }
   ],
   "source": [
    "accuracy=0\n",
    "for i,test_group in enumerate(dist_df['test group']):\n",
    "    right =set(literal_eval(test_group)) & set(literal_eval(dist_df.loc[i,'pred group']))\n",
    "    if len(right)>0:\n",
    "        accuracy+=1\n",
    "        \n",
    "accuracy= accuracy/dist_df.shape[0]\n",
    "\n",
    "print(\"The accuracy is: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words dataframe <br>- including the prevalence of each word in files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sum_WORDinFile(file,lenFile):\n",
    "\n",
    "    relative_prevalence_of_words_file=[]    \n",
    "    \n",
    "    for word in df[\"word\"]: \n",
    "        \n",
    "        countWord = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), file))\n",
    "        relative_prevalence_of_words_file.append(float(countWord/lenFile))\n",
    "\n",
    "\n",
    "    return relative_prevalence_of_words_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative prevalence from each word in each file before treatment\n",
    "filesBefore_relat_prev_words=[]\n",
    "\n",
    "for file in beforeArr:\n",
    "    \n",
    "    lenFile= len(file.split())\n",
    "    file_relat_prev= Sum_WORDinFile(file,lenFile)\n",
    "    filesBefore_relat_prev_words.append(file_relat_prev)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg for each word in before treatment files\n",
    "before_avrege_word=[]\n",
    "\n",
    "for i,word in enumerate(df['word']):\n",
    "    sum1=0.0\n",
    "    for relat in filesBefore_relat_prev_words:\n",
    "        sum1+=relat[i]\n",
    "    \n",
    "    before_avrege_word.append(float((sum1/len(beforeArr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative prevalence from each word in each file after treatment\n",
    "filesAfter_relat_prev_words=[]\n",
    "\n",
    "for file in afterArr:\n",
    "    \n",
    "    lenFile= len(file.split())\n",
    "    file_relat_prev= Sum_WORDinFile(file,lenFile)\n",
    "    filesAfter_relat_prev_words.append(file_relat_prev)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg for each word in after treatment files\n",
    "after_avrege_word=[]\n",
    "\n",
    "for i,word in enumerate(df['word']):\n",
    "    sum1=0.0\n",
    "    for relat in filesAfter_relat_prev_words:\n",
    "        sum1=sum1+relat[i]\n",
    "\n",
    "    after_avrege_word.append(float((sum1/len(afterArr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary ={ \"word\": df['word'],\n",
    "             \"Avg word Before\": before_avrege_word,\n",
    "             \"Avg word After\": after_avrege_word,   \n",
    "}\n",
    "\n",
    "Avg_words_df= pd.DataFrame.from_dict(dictionary)\n",
    "Avg_words_df.to_excel(\"averageWord.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Avg word Before</th>\n",
       "      <th>Avg word After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conciousword</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>0.037275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pst1fst</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.027506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>לא</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>0.024660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>זה</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.018088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>אני</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.015629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Avg word Before  Avg word After\n",
       "0  conciousword         0.036396        0.037275\n",
       "1       pst1fst         0.027635        0.027506\n",
       "2            לא         0.028374        0.024660\n",
       "3            זה         0.017402        0.018088\n",
       "4           אני         0.015712        0.015629"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_words_df = pd.read_excel(\"averageWord.xlsx\")\n",
    "if \"Unnamed: 0\" in Avg_words_df.columns:\n",
    "    Avg_words_df = Avg_words_df.drop(columns=\"Unnamed: 0\")\n",
    "Avg_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prominent words from each group  <br>- The ratio of the prevalence of a word in a particular group to the sum of the total prevalence of the words in that group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_words_df = pd.read_excel(\"averageWord.xlsx\")\n",
    "if \"Unnamed: 0\" in Avg_words_df.columns:\n",
    "    Avg_words_df = Avg_words_df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Avg word Before</th>\n",
       "      <th>Avg word After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conciousword</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>0.037275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pst1fst</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.027506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>לא</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>0.024660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>זה</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.018088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>אני</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.015629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Avg word Before  Avg word After\n",
       "0  conciousword         0.036396        0.037275\n",
       "1       pst1fst         0.027635        0.027506\n",
       "2            לא         0.028374        0.024660\n",
       "3            זה         0.017402        0.018088\n",
       "4           אני         0.015712        0.015629"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other': 0,\n",
       " '1st Body': 0,\n",
       " 'Verb': 0,\n",
       " 'Past': 0,\n",
       " 'Adverb': 0,\n",
       " 'Noun': 0,\n",
       " 'ConciousWord': 0,\n",
       " 'Present': 0,\n",
       " 'Adjective': 0,\n",
       " 'Name': 0,\n",
       " 'Emotion': 0,\n",
       " 'Infinitive': 0,\n",
       " 'Future': 0}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_prev_word_for_each_group_before = {key: 0 for key in groups.keys()}\n",
    "sum_of_prev_word_for_each_group_after = {key: 0 for key in groups.keys()}\n",
    "sum_of_prev_word_for_each_group_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in Avg_words_df.iterrows():\n",
    "    for key,val in groups.items():\n",
    "        if row[\"word\"] in val:\n",
    "            sum_of_prev_word_for_each_group_after[key]+=row[\"Avg word After\"]\n",
    "            sum_of_prev_word_for_each_group_before[key]+=row[\"Avg word Before\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_before = {}\n",
    "top_20_after = {}\n",
    "\n",
    "for key,val in groups.items():\n",
    "    temp_before=[]\n",
    "    temp_after=[]\n",
    "    \n",
    "    for word in val:\n",
    "        index = Avg_words_df[\"word\"][Avg_words_df[\"word\"] == word].index[0]\n",
    "        temp_before.append(tuple([word, Avg_words_df[\"Avg word Before\"][index] / sum_of_prev_word_for_each_group_before[key]]))\n",
    "        temp_after.append(tuple([word, Avg_words_df[\"Avg word After\"][index] / sum_of_prev_word_for_each_group_after[key]]))\n",
    "        \n",
    "    higher_prev_before = sorted([tup[1] for tup in temp_before], reverse=True)[:20]    \n",
    "    top_20_before[key] = [tup[0] for tup in temp_before if tup[1] in higher_prev_before]\n",
    "    \n",
    "    higher_prev_after = sorted([tup[1] for tup in temp_after], reverse=True)[:20]  \n",
    "    top_20_after[key] = [tup[0] for tup in temp_after if tup[1] in higher_prev_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " group  Other  :\n",
      "לא\n",
      "זה\n",
      "את\n",
      "הוא\n",
      "של\n",
      "היא\n",
      "מה\n",
      "אבל\n",
      "על\n",
      "עם\n",
      "כבר\n",
      "כי\n",
      "לה\n",
      "לו\n",
      "אותו\n",
      "שהוא\n",
      "שהיא\n",
      "אותה\n",
      "משהו\n",
      "כאילו\n",
      "\n",
      "\n",
      " group  1st Body  :\n",
      "אני\n",
      "לי\n",
      "שלי\n",
      "ואני\n",
      "שאני\n",
      "הייתי\n",
      "אמרתי\n",
      "אותי\n",
      "יודעת\n",
      "אנחנו\n",
      "לנו\n",
      "ואמרתי\n",
      "ראיתי\n",
      "הבנתי\n",
      "התקשרתי\n",
      "ידעתי\n",
      "רציתי\n",
      "הרגשתי\n",
      "חשבתי\n",
      "אליי\n",
      "\n",
      "\n",
      " group  Verb  :\n",
      "היה\n",
      "הייתה\n",
      "הייתי\n",
      "שם\n",
      "אמרתי\n",
      "אמר\n",
      "יודעת\n",
      "היו\n",
      "אמרה\n",
      "אומרת\n",
      "רוצה\n",
      "קרה\n",
      "אמרו\n",
      "אומר\n",
      "ראיתי\n",
      "שהיה\n",
      "נראה\n",
      "ידעתי\n",
      "בא\n",
      "זוכר\n",
      "\n",
      "\n",
      " group  Past  :\n",
      "היה\n",
      "הייתה\n",
      "הייתי\n",
      "שם\n",
      "אמרתי\n",
      "אמר\n",
      "היו\n",
      "אמרה\n",
      "קרה\n",
      "אמרו\n",
      "ואמרתי\n",
      "ראיתי\n",
      "הבנתי\n",
      "שהיה\n",
      "התקשרתי\n",
      "נראה\n",
      "ידעתי\n",
      "רציתי\n",
      "היינו\n",
      "חשבתי\n",
      "\n",
      "\n",
      " group  Adverb  :\n",
      "אז\n",
      "ואז\n",
      "מאוד\n",
      "שם\n",
      "כמה\n",
      "כזה\n",
      "ממש\n",
      "אחרי\n",
      "יותר\n",
      "טוב\n",
      "שלא\n",
      "פשוט\n",
      "יש\n",
      "בעצם\n",
      "קצת\n",
      "בסדר\n",
      "ככה\n",
      "קשה\n",
      "הרבה\n",
      "באמת\n",
      "\n",
      "\n",
      " group  Noun  :\n",
      "כל\n",
      "אמא\n",
      "שם\n",
      "ממש\n",
      "אבא\n",
      "יום\n",
      "טוב\n",
      "בבית\n",
      "פעם\n",
      "יש\n",
      "הזמן\n",
      "היום\n",
      "אנשים\n",
      "חולים\n",
      "דבר\n",
      "זמן\n",
      "הבית\n",
      "שיש\n",
      "שעה\n",
      "אדם\n",
      "\n",
      "\n",
      " group  ConciousWord  :\n",
      "אה\n",
      "הבנתי\n",
      "נכון\n",
      "אמ\n",
      "אממ\n",
      "לעצמי\n",
      "אהה\n",
      "החלטתי\n",
      "ואה\n",
      "ההכרה\n",
      "מממ\n",
      "שאה\n",
      "כמוני\n",
      "וכשאני\n",
      "ממ\n",
      "אםם\n",
      "הממ\n",
      "אמממ\n",
      "ההה\n",
      "ואמ\n",
      "הדחקתי\n",
      "וכמדומני\n",
      "\n",
      "\n",
      " group  Present  :\n",
      "זוכרת\n",
      "יודעת\n",
      "אומרת\n",
      "רוצה\n",
      "צריך\n",
      "חושבת\n",
      "אומר\n",
      "יכול\n",
      "צריכה\n",
      "קורה\n",
      "בא\n",
      "זוכר\n",
      "יכולה\n",
      "יודע\n",
      "באה\n",
      "מנסה\n",
      "הולכת\n",
      "הולך\n",
      "חושב\n",
      "זזה\n",
      "\n",
      "\n",
      " group  Adjective  :\n",
      "טוב\n",
      "פשוט\n",
      "אחד\n",
      "הביתה\n",
      "באותו\n",
      "קצת\n",
      "בסדר\n",
      "נורא\n",
      "קשה\n",
      "הרבה\n",
      "צריכים\n",
      "מיני\n",
      "נמרץ\n",
      "אחרת\n",
      "האחרון\n",
      "רע\n",
      "רגיל\n",
      "ופשוט\n",
      "גרוע\n",
      "הרפואי\n",
      "\n",
      "\n",
      " group  Name  :\n",
      "בן\n",
      "אור\n",
      "איתי\n",
      "אדם\n",
      "רעות\n",
      "משה\n",
      "אלי\n",
      "טובה\n",
      "דוד\n",
      "יוסי\n",
      "שאולי\n",
      "שני\n",
      "תקווה\n",
      "מוישה\n",
      "זיו\n",
      "עלי\n",
      "דין\n",
      "עמית\n",
      "איתן\n",
      "ודולב\n",
      "\n",
      "\n",
      " group  Emotion  :\n",
      "הרגשתי\n",
      "לב\n",
      "מרגיש\n",
      "תקווה\n",
      "בכיתי\n",
      "שמח\n",
      "מרגישה\n",
      "לבכות\n",
      "הרגשה\n",
      "שמחה\n",
      "כאב\n",
      "אוהבת\n",
      "בלב\n",
      "בוכים\n",
      "הכאב\n",
      "בשמחה\n",
      "אוהב\n",
      "בצעקות\n",
      "ובכה\n",
      "עצובים\n",
      "\n",
      "\n",
      " group  Infinitive  :\n",
      "ללכת\n",
      "לדבר\n",
      "ליד\n",
      "לבוא\n",
      "להגיע\n",
      "לראות\n",
      "לקחת\n",
      "להתקשר\n",
      "להבין\n",
      "לעבור\n",
      "להיפרד\n",
      "להעביר\n",
      "להחזיק\n",
      "לנשום\n",
      "לנסוע\n",
      "לאכול\n",
      "למות\n",
      "לשכנע\n",
      "לקום\n",
      "לטיפול\n",
      "\n",
      "\n",
      " group  Future  :\n",
      "יהיה\n",
      "שתי\n",
      "תבוא\n",
      "שיהיה\n",
      "יקרה\n",
      "תהיה\n",
      "נגיד\n",
      "יחזור\n",
      "יבואו\n",
      "שתהיה\n",
      "לכי\n",
      "שיקח\n",
      "תדחפי\n",
      "אהיה\n",
      "ילך\n",
      "שנדע\n",
      "ייקח\n",
      "ושנצא\n",
      "תזוז\n",
      "שנשב\n"
     ]
    }
   ],
   "source": [
    "for key,val in top_20_before.items():\n",
    "    print(\"\\n\\n\",\"group \",key,\" :\")\n",
    "    for word in val:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " group  Other  :\n",
      "לא\n",
      "זה\n",
      "את\n",
      "הוא\n",
      "של\n",
      "היא\n",
      "מה\n",
      "אבל\n",
      "על\n",
      "עם\n",
      "כבר\n",
      "כי\n",
      "לה\n",
      "לו\n",
      "גם\n",
      "אותו\n",
      "שהוא\n",
      "שהיא\n",
      "שזה\n",
      "או\n",
      "\n",
      "\n",
      " group  1st Body  :\n",
      "אני\n",
      "לי\n",
      "שלי\n",
      "ואני\n",
      "שאני\n",
      "הייתי\n",
      "אמרתי\n",
      "אותי\n",
      "יודעת\n",
      "אנחנו\n",
      "לנו\n",
      "ואמרתי\n",
      "ראיתי\n",
      "הבנתי\n",
      "רציתי\n",
      "הרגשתי\n",
      "שלנו\n",
      "שאנחנו\n",
      "נכנסתי\n",
      "הלכתי\n",
      "\n",
      "\n",
      " group  Verb  :\n",
      "היה\n",
      "הייתה\n",
      "הייתי\n",
      "שם\n",
      "אמרתי\n",
      "אמר\n",
      "יודעת\n",
      "היו\n",
      "אמרה\n",
      "אומרת\n",
      "רוצה\n",
      "צריך\n",
      "קרה\n",
      "אמרו\n",
      "חושבת\n",
      "אומר\n",
      "הבנתי\n",
      "רציתי\n",
      "הרגשתי\n",
      "זוכר\n",
      "\n",
      "\n",
      " group  Past  :\n",
      "היה\n",
      "הייתה\n",
      "הייתי\n",
      "שם\n",
      "אמרתי\n",
      "אמר\n",
      "היו\n",
      "אמרה\n",
      "קרה\n",
      "אמרו\n",
      "ואמרתי\n",
      "ראיתי\n",
      "הגיע\n",
      "הבנתי\n",
      "שהיה\n",
      "נראה\n",
      "רציתי\n",
      "הרגשתי\n",
      "נכנסתי\n",
      "הלכתי\n",
      "\n",
      "\n",
      " group  Adverb  :\n",
      "אז\n",
      "ואז\n",
      "מאוד\n",
      "שם\n",
      "כמה\n",
      "כזה\n",
      "ממש\n",
      "אחרי\n",
      "יותר\n",
      "טוב\n",
      "שלא\n",
      "פשוט\n",
      "יש\n",
      "בעצם\n",
      "עכשיו\n",
      "קצת\n",
      "כנראה\n",
      "קשה\n",
      "הרבה\n",
      "בדיוק\n",
      "\n",
      "\n",
      " group  Noun  :\n",
      "כל\n",
      "אמא\n",
      "שם\n",
      "ממש\n",
      "אבא\n",
      "יום\n",
      "טוב\n",
      "בבית\n",
      "פעם\n",
      "יש\n",
      "הזמן\n",
      "היום\n",
      "הכל\n",
      "אנשים\n",
      "לחדר\n",
      "חולים\n",
      "דבר\n",
      "לבית\n",
      "דברים\n",
      "אח\n",
      "\n",
      "\n",
      " group  ConciousWord  :\n",
      "אה\n",
      "הבנתי\n",
      "נכון\n",
      "אמ\n",
      "אממ\n",
      "לעצמי\n",
      "אהה\n",
      "החלטתי\n",
      "ואה\n",
      "ההכרה\n",
      "מממ\n",
      "שאה\n",
      "כמוני\n",
      "וכשאני\n",
      "ממ\n",
      "אםם\n",
      "הממ\n",
      "אמממ\n",
      "ההה\n",
      "ואמ\n",
      "הדחקתי\n",
      "וכמדומני\n",
      "\n",
      "\n",
      " group  Present  :\n",
      "זוכרת\n",
      "יודעת\n",
      "אומרת\n",
      "רוצה\n",
      "צריך\n",
      "חושבת\n",
      "אומר\n",
      "יכול\n",
      "צריכה\n",
      "קורה\n",
      "לך\n",
      "בא\n",
      "רואה\n",
      "זוכר\n",
      "יכולה\n",
      "יודע\n",
      "באה\n",
      "מנסה\n",
      "מבין\n",
      "עובד\n",
      "\n",
      "\n",
      " group  Adjective  :\n",
      "טוב\n",
      "פשוט\n",
      "אחד\n",
      "הביתה\n",
      "באותו\n",
      "קצת\n",
      "בסדר\n",
      "נורא\n",
      "קשה\n",
      "הרבה\n",
      "נכון\n",
      "צריכים\n",
      "אחר\n",
      "גדול\n",
      "טובה\n",
      "מיני\n",
      "מוזר\n",
      "נמרץ\n",
      "קרוב\n",
      "חזק\n",
      "\n",
      "\n",
      " group  Name  :\n",
      "בן\n",
      "אור\n",
      "איתי\n",
      "אדם\n",
      "רעות\n",
      "משה\n",
      "אלי\n",
      "טובה\n",
      "דוד\n",
      "שאולי\n",
      "שני\n",
      "צביקה\n",
      "זיו\n",
      "קובי\n",
      "נתן\n",
      "אברי\n",
      "שצביקה\n",
      "נמרוד\n",
      "דולב\n",
      "קרן\n",
      "\n",
      "\n",
      " group  Emotion  :\n",
      "הרגשתי\n",
      "לב\n",
      "מרגיש\n",
      "תקווה\n",
      "סליחה\n",
      "בכיתי\n",
      "שמח\n",
      "מרגישה\n",
      "לבכות\n",
      "הרגשה\n",
      "רגשות\n",
      "אהב\n",
      "שמחה\n",
      "כאב\n",
      "אהבה\n",
      "אוהבת\n",
      "בוכים\n",
      "בכי\n",
      "והרגשתי\n",
      "כאבים\n",
      "\n",
      "\n",
      " group  Infinitive  :\n",
      "ללכת\n",
      "לדבר\n",
      "ליד\n",
      "לבוא\n",
      "להגיע\n",
      "לראות\n",
      "לקחת\n",
      "להתקשר\n",
      "לצאת\n",
      "לתת\n",
      "לישון\n",
      "להבין\n",
      "לספר\n",
      "לעזור\n",
      "להישאר\n",
      "להתחיל\n",
      "להודיע\n",
      "לקבל\n",
      "לנשום\n",
      "לזהות\n",
      "\n",
      "\n",
      " group  Future  :\n",
      "יהיה\n",
      "שתי\n",
      "תבוא\n",
      "שיהיה\n",
      "יקרה\n",
      "נגיד\n",
      "אבוא\n",
      "אעשה\n",
      "אחיה\n",
      "תראי\n",
      "תדחפי\n",
      "נמרוד\n",
      "אגיד\n",
      "תסביר\n",
      "אגיע\n",
      "יפתח\n",
      "תצא\n",
      "ייסע\n",
      "יראה\n",
      "תיסע\n"
     ]
    }
   ],
   "source": [
    "for key,val in top_20_after.items():\n",
    "    print(\"\\n\\n\",\"group \",key,\" :\")\n",
    "    for word in val:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### -----------------------------------------------------------------------------------------------------------------------------------------------------------Everything we tried about sentences was irrelevant. Because in the text there is no proper division of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word per sentences dataframe<br>- including average occurrences of each word in all sentences in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'[^.!]+')\n",
    "\n",
    "#The number of sentences a word appears divided by the number of sentences in the file\n",
    "def  OccurrencesOfEachWordInAllSentences(file):\n",
    "    \n",
    "    sentences_in_file = list(map(str.strip, tokenizer.tokenize(file))) \n",
    "    sentences_amount = len([ sent for sent in sentences_in_file if sent.split()!=[] ])\n",
    "    word_instance_counts = {}\n",
    "    \n",
    "    for i,word in enumerate(df[\"word\"]):\n",
    "        word_instance_counts[word] = 0\n",
    "        for sent in sentences_in_file:\n",
    "            if word in sent.split():\n",
    "                word_instance_counts[word] += 1\n",
    "        word_instance_counts[word] /= sentences_amount\n",
    "    \n",
    "    return word_instance_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_files = {}\n",
    "before_files = {}\n",
    "\n",
    "for i,after_file in enumerate(afterArr):\n",
    "    after_file = OccurrencesOfEachWordInAllSentences(after_file)\n",
    "    before_file = OccurrencesOfEachWordInAllSentences(beforeArr[i])\n",
    "    for word in df['word']:\n",
    "        after_files[word] = after_files.get(word,0) + after_file.get(word,0)\n",
    "        before_files[word] = before_files.get(word,0) + before_file.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgWordInSentences_df= pd.DataFrame(columns=['word','avg word in sentences before','avg word in sentences after','dist'], index=df.index)\n",
    "\n",
    "for i,word in enumerate(df['word']):\n",
    "    avgWordInSentences_df.loc[i , 'word'] = word\n",
    "    avgWordInSentences_df.loc[i , 'avg word in sentences before'] = before_files[word]/len(beforeArr)\n",
    "    avgWordInSentences_df.loc[i , 'avg word in sentences after'] = after_files[word]/len(afterArr)\n",
    "    avgWordInSentences_df.loc[i , 'dist'] = avgWordInSentences_df['avg word in sentences before'][i] - avgWordInSentences_df['avg word in sentences after'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgWordInSentences_df.to_excel(\"avgWordInSentences_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similar sentences dataframe <br>- Includes finding and comparing similar sentences between files before and after treatment for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(afterArr):\n",
    "    match = re.search(r'\\d+(.)\\d+(.)\\d+', file)\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " afterArr[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'[^.!]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_file_sentensecs = list(map(str.strip, tokenizer.tokenize(beforeArr[18]))) \n",
    "after_file_sentensecs = list(map(str.strip, tokenizer.tokenize(afterArr[18]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sen in enumerate(before_file_sentensecs):\n",
    "    print(i,\" : \")\n",
    "    for s in sen.split():\n",
    "        print(s,\"\\n\")\n",
    "    print(\"\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sen in enumerate(after_file_sentensecs):\n",
    "    print(i,\" : \")\n",
    "    for s in sen.split():\n",
    "        print(s,\"\\n\")\n",
    "    print(\"\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(after_file_sentensecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(before_file_sentensecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "most_similar = {}\n",
    "for i,a_sen in enumerate(after_file_sentensecs):\n",
    "    temp = {}\n",
    "    for  j,b_sen in enumerate(before_file_sentensecs):\n",
    "        temp[b_sen] = len( set(b_sen.split()) & set(a_sen.split()) ) \n",
    "    b_most_similar_to_a = max(temp.items(), key=operator.itemgetter(1))[0] \n",
    "    most_similar[a_sen] = b_most_similar_to_a  \n",
    "    print(a_sen,\"\\n\")\n",
    "    print(b_most_similar_to_a)\n",
    "    print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### -----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of files before and after treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def Visualization(vectors):\n",
    "    # Set data\n",
    "    pca = PCA(n_components=2)\n",
    "    before_vectors = vectors.copy()[::2]\n",
    "    after_vectors = vectors.copy()[1::2]\n",
    "\n",
    "    x_pca = pca.fit_transform(before_vectors)\n",
    "    y_pca = pca.fit_transform(after_vectors)\n",
    "    \n",
    "    plt.xlabel('Principal component 1')\n",
    "    plt.ylabel('Principal component 2')\n",
    "    \n",
    "    plt.scatter(x_pca[:,0], x_pca[:, 1], marker=\"o\", cmap=\"magma\")\n",
    "    plt.scatter(y_pca[:,0], y_pca[:, 1], marker=\"o\", cmap=\"magma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def our_train_and_split(target,files_vec,ratio): \n",
    "    \n",
    "    size_train =int(len(files_vec)*ratio)\n",
    "    if size_train%2 != 0:\n",
    "        size_train+=1  \n",
    "    print(size_train)\n",
    "    \n",
    "    even_index_in_files_vec = [i for i in range(0,len(files_vec)) if i%2==0]\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    index_choose = [] \n",
    "    \n",
    "    for i in range(0,int(size_train/2)):\n",
    "        \n",
    "        rand_row = random.choice(even_index_in_files_vec)\n",
    "\n",
    "        x_train.append(files_vec[rand_row])\n",
    "        x_train.append(files_vec[rand_row+1])\n",
    "        \n",
    "        y_train.append(target[rand_row])\n",
    "        y_train.append(target[rand_row+1])\n",
    "        \n",
    "        even_index_in_files_vec.remove(rand_row)\n",
    "        index_choose.append(rand_row)\n",
    "        index_choose.append(rand_row+1)\n",
    "        \n",
    "    x_test = [files_vec[row] for row in range(0,len(files_vec)) if row not in index_choose]\n",
    "    y_test = [target[row] for row in range(0,len(target)) if row not in index_choose]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try different algorithms and different parameters\n",
    "model_params = {\n",
    "    'logistic_regression' : {\n",
    "        'model' : LogisticRegression(),\n",
    "        'params' : {\n",
    "            'penalty' : ['l2','l1'],\n",
    "            'C' : [100, 10, 1.0, 0.1, 0.01]\n",
    "        }\n",
    "    },\n",
    "    'svm':{\n",
    "        'model' : svm.SVC(gamma='auto' ),\n",
    "        'params' : {\n",
    "            'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "            'C' : [0.001, 0.05 ,0.01, 0.1, 1, 10, 100, 500, 1000],\n",
    "            'gamma' : ['scale']\n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [10, 100, 1000],\n",
    "            'max_features' : ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'knn' : {\n",
    "        'model' : KNeighborsClassifier(),\n",
    "        'params' : {\n",
    "            'n_neighbors' : [3,5,7,9,11,13,15,17,19,21],\n",
    "            'weights' : ['uniform', 'distance',None],\n",
    "            'metric' : ['euclidean', 'manhattan', 'minkowski']\n",
    "        }\n",
    "    },\n",
    "    'decision_tree' : {\n",
    "        'model' : DecisionTreeClassifier(),\n",
    "        'params' : {\n",
    "            'max_depth' : [2,3,10,15,21],\n",
    "            'min_samples_split' : [2,3,10,15,21]\n",
    "        } \n",
    "     },\n",
    "     'bagged_decision_trees' : {\n",
    "        'model' : BaggingClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [10, 100, 1000]\n",
    "        }\n",
    "    },\n",
    "    'stochastic_gradient_boosting' : {\n",
    "        'model' : GradientBoostingClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [10, 100, 1000],\n",
    "            'learning_rate' : [0.001, 0.01, 0.1],\n",
    "            'subsample' : [0.5, 0.7, 1.0],\n",
    "            'max_depth' : [3, 7, 9]\n",
    "        }\n",
    "    },\n",
    "    'sgd' : {\n",
    "        'model' : SGDClassifier(),\n",
    "        'params' : {\n",
    "            'penalty':('l1','l2')\n",
    "        } \n",
    "     },\n",
    "     'naive_bayes' : {\n",
    "        'model' : MultinomialNB(),\n",
    "        'params' : {\n",
    "            \n",
    "        } \n",
    "     }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def GridSearchCV_TrainSetResult(x_train, y_train, x_test, y_test, num_split_cv):\n",
    "    scores = []\n",
    "\n",
    "    for model_name, mp in model_params.items():\n",
    "        #we decided shuffle = False , for keeping each patient's file one next to each other \n",
    "        cv = KFold(n_splits=num_split_cv, shuffle= False , random_state= None)\n",
    "        gs = GridSearchCV(mp['model'], mp['params'], scoring=\"accuracy\" ,cv=cv, n_jobs=-1, return_train_score=False)\n",
    "        gs = gs.fit(x_train,y_train)\n",
    "        scores.append({\n",
    "            'model' : model_name,\n",
    "            'best_score' : gs.best_score_,\n",
    "            'best_params' : gs.best_params_,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Classifier(x_train, y_train, x_test, y_test, met, k_n, w):\n",
    "    #Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(metric=met, n_neighbors=k_n ,weights=w)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = knn.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier(x_train, y_train, x_test, y_test, k, c, g):\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel=k,C=c, gamma=g)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RANDOMFFOREST_Classifier(x_train, y_train, x_test, y_test, f, n_e):\n",
    "    #Create Random Forest Classifier\n",
    "    forest = RandomForestClassifier(max_features=f, n_estimators=n_e)\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    forest.fit(x_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = forest.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing----------Classification test by fictitious vectors----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_vec = []\n",
    "for i in range(40):\n",
    "    if i%2==0:\n",
    "        fic_vec.append([i* var for var in [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]])\n",
    "    else:\n",
    "        fic_vec.append([i* var for var in [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0]])\n",
    "fic_target= [0 if i%2==0 else 1 for i in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Visualization(fic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = our_train_and_split(fic_target,fic_vec,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3, 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    1.000000   \n",
       "1                           svm    1.000000   \n",
       "2                 random_forest    0.966667   \n",
       "3                           knn    1.000000   \n",
       "4                 decision_tree    0.966667   \n",
       "5         bagged_decision_trees    0.966667   \n",
       "6  stochastic_gradient_boosting    0.966667   \n",
       "7                           sgd    0.966667   \n",
       "8                   naive_bayes    1.000000   \n",
       "\n",
       "                                         best_params  \n",
       "0                        {'C': 100, 'penalty': 'l2'}  \n",
       "1  {'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...  \n",
       "2       {'max_features': 'sqrt', 'n_estimators': 10}  \n",
       "3  {'metric': 'euclidean', 'n_neighbors': 3, 'wei...  \n",
       "4           {'max_depth': 2, 'min_samples_split': 2}  \n",
       "5                               {'n_estimators': 10}  \n",
       "6  {'learning_rate': 0.001, 'max_depth': 3, 'n_es...  \n",
       "7                                  {'penalty': 'l1'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(x_train, y_train, x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df[\"best_params\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 3, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Classification try:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vectors from the prevalence of each group in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Noun Before</th>\n",
       "      <th>1st Body Before</th>\n",
       "      <th>ConciousWord Before</th>\n",
       "      <th>Verb Before</th>\n",
       "      <th>Past Before</th>\n",
       "      <th>Present Before</th>\n",
       "      <th>Future Before</th>\n",
       "      <th>Other Before</th>\n",
       "      <th>Adjective Before</th>\n",
       "      <th>...</th>\n",
       "      <th>Verb Ratio</th>\n",
       "      <th>Past Ratio</th>\n",
       "      <th>Present Ratio</th>\n",
       "      <th>Future Ratio</th>\n",
       "      <th>Other Ratio</th>\n",
       "      <th>Adjective Ratio</th>\n",
       "      <th>Adverb Ratio</th>\n",
       "      <th>Infinitive Ratio</th>\n",
       "      <th>Emotion Ratio</th>\n",
       "      <th>Name Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191</td>\n",
       "      <td>0.991</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.341</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.131</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.429</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.107</td>\n",
       "      <td>3.333</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.152</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.511</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.839</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.182</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.632</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient  Noun Before  1st Body Before  ConciousWord Before  Verb Before  \\\n",
       "0        0        0.225            0.077                0.031        0.187   \n",
       "1        1        0.217            0.114                0.010        0.189   \n",
       "2        2        0.156            0.096                0.001        0.186   \n",
       "3        3        0.168            0.091                0.008        0.171   \n",
       "4        4        0.242            0.094                0.015        0.156   \n",
       "\n",
       "   Past Before  Present Before  Future Before  Other Before  Adjective Before  \\\n",
       "0        0.112           0.075          0.000         0.311             0.059   \n",
       "1        0.100           0.071          0.018         0.243             0.044   \n",
       "2        0.131           0.050          0.014         0.279             0.036   \n",
       "3        0.104           0.053          0.014         0.281             0.068   \n",
       "4        0.099           0.044          0.013         0.252             0.068   \n",
       "\n",
       "   ...  Verb Ratio  Past Ratio  Present Ratio  Future Ratio  Other Ratio  \\\n",
       "0  ...       1.191       0.991          2.206         0.000        1.280   \n",
       "1  ...       1.005       1.010          1.000         1.000        0.946   \n",
       "2  ...       0.903       0.766          1.429         1.750        1.187   \n",
       "3  ...       1.082       1.010          1.152         1.400        1.115   \n",
       "4  ...       1.020       0.971          0.863         1.182        0.920   \n",
       "\n",
       "   Adjective Ratio  Adverb Ratio  Infinitive Ratio  Emotion Ratio  Name Ratio  \n",
       "0            1.341         0.778             0.906          1.625       0.667  \n",
       "1            0.978         1.131             0.857          0.800       1.000  \n",
       "2            1.800         1.109             1.107          3.333       0.300  \n",
       "3            1.511         0.918             0.839          2.500       1.125  \n",
       "4            1.333         0.861             1.632          0.778       1.800  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientsdf= pd.read_excel(\"before_and_after.xlsx\")\n",
    "if \"Unnamed: 0\" in patientsdf.columns:\n",
    "    patientsdf = patientsdf.drop(columns=\"Unnamed: 0\")\n",
    "patientsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient', 'Noun Before', '1st Body Before', 'ConciousWord Before',\n",
       "       'Verb Before', 'Past Before', 'Present Before', 'Future Before',\n",
       "       'Other Before', 'Adjective Before', 'Adverb Before',\n",
       "       'Infinitive Before', 'Emotion Before', 'Name Before', 'Noun After',\n",
       "       '1st Body After', 'ConciousWord After', 'Verb After', 'Past After',\n",
       "       'Present After', 'Future After', 'Other After', 'Adjective After',\n",
       "       'Adverb After', 'Infinitive After', 'Emotion After', 'Name After',\n",
       "       'Noun Ratio', '1st Body Ratio', 'ConciousWord Ratio', 'Verb Ratio',\n",
       "       'Past Ratio', 'Present Ratio', 'Future Ratio', 'Other Ratio',\n",
       "       'Adjective Ratio', 'Adverb Ratio', 'Infinitive Ratio', 'Emotion Ratio',\n",
       "       'Name Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientsdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vectors = []\n",
    "target = []\n",
    "for i in range(0,len(afterArr)):\n",
    "    target.append(0)\n",
    "    target.append(1)\n",
    "    file_vectors.append([patientsdf.iloc[i,col] for col in range(1,14)])\n",
    "    file_vectors.append([patientsdf.iloc[i,col] for col in range(14,27)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.225,\n",
       " 0.077,\n",
       " 0.031,\n",
       " 0.187,\n",
       " 0.112,\n",
       " 0.075,\n",
       " 0.0,\n",
       " 0.311,\n",
       " 0.059,\n",
       " 0.07,\n",
       " 0.029,\n",
       " 0.013,\n",
       " 0.002]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Visualization(file_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = our_train_and_split(target,file_vectors,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sgd</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>{'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    0.566667   \n",
       "1                           svm    0.600000   \n",
       "2                 random_forest    0.733333   \n",
       "3                           knn    0.633333   \n",
       "4                 decision_tree    0.533333   \n",
       "5         bagged_decision_trees    0.566667   \n",
       "6  stochastic_gradient_boosting    0.666667   \n",
       "7                           sgd    0.533333   \n",
       "8                   naive_bayes    0.666667   \n",
       "\n",
       "                                         best_params  \n",
       "0                        {'C': 100, 'penalty': 'l2'}  \n",
       "1       {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}  \n",
       "2       {'max_features': 'log2', 'n_estimators': 10}  \n",
       "3  {'metric': 'manhattan', 'n_neighbors': 5, 'wei...  \n",
       "4           {'max_depth': 2, 'min_samples_split': 3}  \n",
       "5                              {'n_estimators': 100}  \n",
       "6  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...  \n",
       "7                                  {'penalty': 'l2'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(x_train, y_train, x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "SVM_Classifier(x_train, y_train, x_test, y_test, 'rbf', 2, 'scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Precision: 0.4\n",
      "Recall: 0.4\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(x_train, y_train, x_test, y_test, 'log2', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Classification Try:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Average-words dataframe that contains the prevalence of all words, we will examine which are the most prominent words, the words with the largest or smallest reduction between patient's files before and after treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Avg word Before</th>\n",
       "      <th>Avg word After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>conciousword</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>0.037275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pst1fst</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.027506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>לא</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>0.024660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>זה</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.018088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>אני</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.015629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Avg word Before  Avg word After\n",
       "0  conciousword         0.036396        0.037275\n",
       "1       pst1fst         0.027635        0.027506\n",
       "2            לא         0.028374        0.024660\n",
       "3            זה         0.017402        0.018088\n",
       "4           אני         0.015712        0.015629"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_words_df = pd.read_excel(\"averageWord.xlsx\")\n",
    "if \"Unnamed: 0\" in avg_words_df.columns:\n",
    "    avg_words_df = avg_words_df.drop(columns=\"Unnamed: 0\")\n",
    "    \n",
    "avg_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = []\n",
    "for i,row in avg_words_df.iterrows():\n",
    "    reduction.append(tuple([ row[\"word\"], row[\"Avg word Before\"]-row[\"Avg word After\"] ]))\n",
    "\n",
    "prominent_words = [ tup[0] for tup in reduction if tup[1] in sorted([tup[1] for tup in reduction], reverse=True)[:10] ]\n",
    "neg_reduction = [ tup[0] for tup in reduction if tup[1] in sorted([tup[1] for tup in reduction])[:10] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 words, 10 words with the highest incidence in pre-treatment files versus post-treatment files, and 10 with the smallest incidence.\n",
    "for w in neg_reduction:\n",
    "    prominent_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['לא',\n",
       " 'spectoken',\n",
       " 'break',\n",
       " 'שלי',\n",
       " 'כל',\n",
       " 'שהיא',\n",
       " 'והוא',\n",
       " 'הביתה',\n",
       " 'לעשות',\n",
       " 'לביה']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 10 words that stand out most in pre-treatment files versus post-treatment files\n",
    "prominent_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conciousword',\n",
       " 'את',\n",
       " 'היה',\n",
       " 'לי',\n",
       " 'pres1st',\n",
       " 'של',\n",
       " 'אבל',\n",
       " 'גם',\n",
       " 'אה',\n",
       " 'חושבת']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 10 words that stand out most in post-treatment files versus pre-treatment files\n",
    "prominent_words[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prominent_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create vector per file.<br> Each vector will contain the prevalence of each of the dominant words. <br>In addition we will add to each vector the prevalence of conciouswords, names, adjective, future and emotions in file .<br>This details we found interesting in patientsdf.<br>Another figure to consider is the length of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumProminentWordinFile(file):\n",
    "\n",
    "    return [sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), file)) / len(file.split()) for word in prominent_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = []\n",
    "file_vectors =[]\n",
    "for i,f_a in enumerate(afterArr):\n",
    "    \n",
    "    #Prevalence of each of the dominant words\n",
    "    vec_before = SumProminentWordinFile(beforeArr[i])\n",
    "    vec_after = SumProminentWordinFile(f_a)\n",
    "    #Prevalence of conciouswords\n",
    "    vec_before.append(patientsdf.loc[i,\"ConciousWord Before\"])\n",
    "    vec_after.append(patientsdf.loc[i,\"ConciousWord After\"])\n",
    "    #Prevalence of names\n",
    "    vec_before.append(patientsdf.loc[i,\"Name Before\"])\n",
    "    vec_after.append(patientsdf.loc[i,\"Name After\"])\n",
    "    #Prevalence of adjective\n",
    "    vec_before.append(patientsdf.loc[i,\"Adjective Before\"])\n",
    "    vec_after.append(patientsdf.loc[i,\"Adjective After\"])\n",
    "    #Prevalence of future\n",
    "    vec_before.append(patientsdf.loc[i,\"Future Before\"])\n",
    "    vec_after.append(patientsdf.loc[i,\"Future After\"])\n",
    "    #Prevalence of emotions\n",
    "    vec_before.append(patientsdf.loc[i,\"Emotion Before\"])\n",
    "    vec_after.append(patientsdf.loc[i,\"Emotion After\"])\n",
    "    #length of a file\n",
    "    vec_before.append(len(beforeArr[i].split()))\n",
    "    vec_after.append(len(f_a.split()))\n",
    "\n",
    "    file_vectors.append(vec_before)\n",
    "    file_vectors.append(vec_after)\n",
    "\n",
    "    #nun patient\n",
    "    patient.append(i+1)\n",
    "    patient.append(i+1)\n",
    "\n",
    "    \n",
    "target = [i%2 for i in range(0,len(file_vectors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7hcVZnn8e+PJISDSg6XoOQkMaFJRxHSBg+IDdM6IARQSETA2DqCYNPODA+29sRJtAXkmR7A2KI09KPIRcALRAwxiJLGAM2oiJwQTLiYIdzMSRgIlwSRAwnhnT/2OqFyUnWyT5261+/zPPVU7VW7ar/rJFVv7bXWXksRgZmZ2VDtVO8AzMysOTmBmJlZWZxAzMysLE4gZmZWFicQMzMry8h6B1BLe+21V0yaNKneYZiZNZVly5Y9GxFjB5a3VQKZNGkSPT099Q7DzKypSHqyWLmbsMzMrCxOIGZmVhYnEDMzK4sTiJmZlcUJxMzMyuIEYmZmZXECMTOzsjiBmJlZWZxArPJWLICLD4DzOrP7FQvqHZGZVUFbXYluNbBiAdx8Nmzuy7Y3rsm2AaadUr+4zKzifAZilbX0/DeSR7/NfVm5mbUUJxCrrI29Qys3s6blBGKVNWb80MrNrGk5gVhlHXkOjOrYtmxUR1ZuZi3FCcQqa9opcPwlMGYCoOz++EvcgW7Wguo6CkvSMcC3gBHAFRFx4YDnRwPXAu8BngM+FhFPSBoFXAEcRFaHayPigpoGb6VNO8UJw6wN1O0MRNII4DLgWGB/4OOS9h+w2xnACxGxH3AxcFEqPxkYHREHkiWXv5c0qRZxm5lZpp5NWIcAqyPisYjYBFwPzBywz0zgmvT4RuBISQICeJOkkUAHsAl4sTZhm5kZ1DeBdAFrCrZ7U1nRfSLiNWAjsCdZMvkz8BTwR+DrEfF8sYNIOlNSj6Se9evXV7YGZmZtrJ4JREXKIuc+hwBbgHHAZOAfJe1b7CARcXlEdEdE99ix260Jb2ZmZapnAukFJhRsjwfWldonNVeNAZ4H/ha4NSI2R8QzwK+B7qpHbGZmW9UzgdwLTJE0WdLOwGxg8YB9FgOnpscnAbdHRJA1Wx2hzJuAQ4E/1ChuMzOjjgkk9WmcBSwBHgYWRMSDks6XdELa7UpgT0mrgS8Ac1P5ZcCbgQfIEtHVEbGiphUwM2tzyn7Qt4fu7u7o6empdxhmZk1F0rKI2K6bwFeim5lZWZxAzMysLE4gZmZWFicQMzMrixOImZmVxQnEzMzK4gRiZmZlcQIxM7OyOIGYmVlZnEDMzKwsTiBmZlYWJxAzMyuLE4iZmZXFCcTMzMriBGJmZmVxAjEzs7I4gZiZWVmcQMzMrCxOIGZmVhYnEDMzK4sTiJmZlcUJxMzMyjKy3gFYdS1avpb5S1axbkMf4zo7mDNjKrOmd9U7LDNrAU4gLWzR8rXMW7iSvs1bAFi7oY95C1cCOImY2bDVtQlL0jGSVklaLWlukedHS7ohPX+PpEkFz02TdLekByWtlLRLLWNvBvOXrNqaPPr1bd7C/CWr6hSRmbWSuiUQSSOAy4Bjgf2Bj0vaf8BuZwAvRMR+wMXARem1I4HvA5+NiHcBHwA21yj0prFuQ9+Qys3MhqKeZyCHAKsj4rGI2ARcD8wcsM9M4Jr0+EbgSEkCjgZWRMTvASLiuYjYgm1jXGfHkMrNzIaingmkC1hTsN2byoruExGvARuBPYG/BELSEkn3SfpiqYNIOlNSj6Se9evXV7QCjW7OjKl0jBqxTVnHqBHMmTG1ThGZWSupZye6ipRFzn1GAocDBwMvA0slLYuIpdvtHHE5cDlAd3f3wPdvaf0d5R6FZWbVUM8E0gtMKNgeD6wrsU9v6vcYAzyfyv8jIp4FkPRz4CBguwTS7mZN73LCMLOqKNmEJWk3SRdIuk7S3w547t8qcOx7gSmSJkvaGZgNLB6wz2Lg1PT4JOD2iAhgCTBN0q4psbwfeKgCMZmZWU6D9YFcTdaE9BNgtqSfSBqdnjt0uAdOfRpnkSWDh4EFEfGgpPMlnZB2uxLYU9Jq4AvA3PTaF4BvkCWh+4H7IuKW4cZkZmb5KftBX+QJ6f6IeHfB9peB44ATgNsi4qDahFg53d3d0dPTU+8wzMyaSupj7h5YPlgfyGhJO0XE6wAR8c+SeoG7gDdXKU4zM2sSgzVh3QwcUVgQEdcA/whsqmZQZmbW+EqegURE0WsrIuJWYErVIjIzs6bg6dzNzKwsTiBmZlaWHSaQgqG7g5aZmVl7yXMGcnfOMjMzayMlO9ElvY1sMsMOSdN5Y16q3YBdaxCbmZk1sMGuA5kBnEY2R9U3Csr/BHypijGZmVkTGGwY7zXANZI+GhE/qWFMZmbWBPLMxvuzNJnipML9I+L8agVlZmaNL08C+SnZQk7LgFerG46ZmTWLPAlkfEQcU/VIzMysqeQZxvsbSQdWPRIzM2sqec5ADgdOk/Q4WROWgIiIaVWNzMzMGlqeBHJs1aMwM7Oms8MmrIh4kmxd8iPS45fzvM7MzFpbnrmwzgX+JzAvFY0Cvl/NoMzMrPHlacL6CDAduA8gItZJektVo7KKWLR8LfOXrGLdhj7GdXYwZ8ZUZk3vqndYZtYi8iSQTRERkgJA0puqHJNVwKLla5m3cCV9m7cAsHZDH/MWrgRwEjGzisjTl7FA0neATkl/B/wS+G51w7Lhmr9k1dbk0a9v8xbmL1lVp4jMrNXs8AwkIr4u6SjgRWAqcE5E3Fb1yGxY1m3oG1K5mdlQ5WnCIiUMJ40mMq6zg7VFksW4zo46RGNmrSjPKKwTJT0iaaOkFyX9SdKLtQjOyjdnxlQ6Ro3Ypqxj1AjmzJhap4jMrNXk6QP5GnBCRIyJiN0i4i0RsVslDi7pGEmrJK2WNLfI86Ml3ZCev0fSpAHPT5T0kqT/UYl4Wsms6V1ccOKBdHV2IKCrs4MLTjzQHehmVjF5mrCejoiHK31gSSOAy4CjgF7gXkmLI+Khgt3OAF6IiP0kzQYuAj5W8PzFwC8qHVurmDW9ywnDzKomTwLpkXQDsIiC6dwjYuEwj30IsDoiHgOQdD0wEyhMIDOB89LjG4FLJSkNK54FPAb8eZhxmJlZGfIkkN3Ipi85uqAsgOEmkC5gTcF2L/DeUvtExGuSNgJ7Suojuzr+KGDQ5itJZwJnAkycOHGYIZuZWb88w3g/XaVjq9jhcu7zVeDiiHhJKrZLwc4RlwOXA3R3dw98fzMzK9MOE4ik8cC/AoeRfXn/CvhcRPQO89i9ZJM09hsPrCuxT6+kkcAY4HmyM5WTJH0N6ARel/RKRFw6zJjMzCynPKOwrgYWA+PImpRuTmXDdS8wRdJkSTsDs9NxCi0GTk2PTwJuj8x/iohJETEJ+Cbwv508zMxqK08CGRsRV0fEa+n2PWDscA8cEa8BZwFLgIeBBRHxoKTzJZ2QdruSrM9jNfAFYLuhvmZmVh95OtGflfRJ4Edp++PAc5U4eET8HPj5gLJzCh6/Apy8g/c4rxKxmJnZ0OQ5AzkdOAX4f+l2UiozM7M2lmcU1h+BE3a0n5mZtZc8c2HtK+lmSeslPSPpp5L2rUVwZmbWuPI0Yf0QWADsQzYS68e80R9iZmZtKk8CUURcVzAK6/tsf8GfmZm1mTwJ5A5JcyVNkvR2SV8EbpG0h6Q9qh1g01qxAC4+AM7rzO5XLKh3RGZmFZVnGG//7Ld/P6D8dLIzEfeHDLRiAdx8NmxOCzptXJNtA0w7pX5xmZlVUJ5RWJNrEUhLWXr+G8mj3+a+rNwJxMxaRJ65sEYAHwImFe4fEd+oXlhNbmOJacJKlZuZNaE8TVg3A68AK4HXqxtOixgzPmu2KlZuZtYi8iSQ8RExreqRtJIjz9m2DwRgVEdWbmbWIvKMwvqFpKN3vJttNe0UOP4SGDMBUHZ//CXu/zCzlpLnDOS3wE2SdgI2ky3yFBGxW1Uja3bTTnHCMLOWlieB/AvwPmBlRPgCQjMzA/I1YT0CPODkYWZmhfKcgTwF3CnpF8Cr/YUexmtm1t7yJJDH023ndDMzM8t1JfpXASS9JduMl6oelZmZNbw864EcIGk58ADwoKRlkt5V/dDMzKyR5WnCuhz4QkTcASDpA8B3gb+uYlxmZi1n0fK1zF+yinUb+hjX2cGcGVOZNb2r3mGVLU8CeVN/8gCIiDslvamKMZmZtZxFy9cyb+FK+jZvAWDthj7mLVwJ0LRJJM8w3sckfSWtBzJJ0j+RdaqbmVlO85es2po8+vVt3sL8JavqFNHw5UkgpwNjgYXpthfw6WoGZWbWatZt6BtSeTPIMwrrBeDsGsRiZtayxnV2sLZIshjX2VGHaCojzyis2yR1FmzvLmlJdcMyM2stc2ZMpWPUiG3KOkaNYM6MqXWKaPjyNGHtFREb+jfSGcnelTi4pGMkrZK0WtLcIs+PlnRDev4eSZNS+VFpOPHKdH9EJeIxM6uWWdO7uODEA+nq7EBAV2cHF5x4YNN2oEO+UVivS5oYEX8EkPR2srXQhyWtdHgZcBTQC9wraXFEPFSw2xnACxGxn6TZwEVka7Q/CxwfEeskHQAsAZr3X8HM2sKs6V1NnTAGypNAvgz8StJ/pO2/Ac6swLEPAVZHxGMAkq4HZgKFCWQmcF56fCNwqSRFxPKCfR4EdpE0OiJexczMaiJPJ/qtkg4CDiVbC+TzEfFsBY7dBRSu+9oLvLfUPhHxmqSNwJ5kZyD9PgosL5U8JJ1JSngTJ06sQNhmZgb5zkBICeNnFT62ih1qKPukKVUuAkqumBgRl5NdTU93d7enpDczq5A8nejV0gtMKNgeD6wrtY+kkcAY4Pm0PR64CfhURDxa9WjNzGwb9Uwg9wJTJE2WtDMwG1g8YJ/FwKnp8UnA7RERaVjxLcC8iPh1zSI2M7OtSjZhSdpjsBdGxPPDOXDq0ziLbATVCOCqiHhQ0vlAT0QsBq4ErpO0muzMY3Z6+VnAfsBXJH0llR0dEc8MJ6a2sWIBLD0fNvbCmPFw5Dlev93MhkylVqqV9DhZf0PRfoiI2LeagVVDd3d39PT01DuM+lqxAG4+GzYXXBE7qgOOv8RJxMyKkrQsIroHlpc8A4mIydUNyepi6fnbJg/Itpee7wRiZkOSaxSWpN2BKcAu/WURcVe1grIq2tg7tHIzsxJ2mEAkfQb4HNkoqfvJrge5G/D0Ic1ozHjYuKZ4uZnZEOQZhfU54GDgyYj4z8B0YH1Vo7LqOfKcrM+j0KiOrNzMbAjyJJBXIuIVyCY3jIg/AM07fWS7m3ZK1mE+ZgKg7N4d6GZWhjx9IL3puotFwG2SXmD7C/6smUw7xQljKDzs2ayoPHNhfSQ9PE/SHWRXg99a1ajMGsXAYc8b12Tb4CRibS/vKKyDgMPJrgv5dURsqmpUVlGLlq9l/pJVrNvQx7jODubMmNpSU0pXlYc9m5WUZ0XCc4BryGbB3Qu4WtI/VTswq4xFy9cyb+FK1m7oI4C1G/qYt3Ali5avrXdozcHDns1KytOJ/nHg4Ig4NyLOJRvG+4nqhmWVMn/JKvo2b9mmrG/zFuYvWVWniJpMqeHNHvZsliuBPEHBBYTAaMCz3zaJdRv6hlRuA3jYs1lJeRLIq8CDkr4n6WrgAeAlSZdIuqS64dlwjevsGFJ5U1uxAC4+AM7rzO5XLBj+e3rYs1lJeTrRb0q3fndWJxSrhjkzpjJv4cptmrE6Ro1gzowWu5SnmqOlPOzZrKg8w3ivqUUgVh2zpnfRteZnTLhvPnvHep7RWNYcNIeDpx9T79Aqy6OlzGpusPVAFkTEKZJWsv1Ss0TEtKpGZpWxYgEHrzwX6APB21jP21aeC5N2b60vVo+WMqu5wc5APpfuP1yLQKxK2uWXuSeJNKu5kp3oEfFUwT5PR8STEfEk8AzFF5myRtQuv8w9Wsqs5vKMwvox8HrB9pZUZs2g2a5jKHcklUdLmdVcnlFYIwunLomITZJ2rmJMVklHnlN8CdtG/GU+3JFUHi1lVlN5zkDWSzqhf0PSTODZ6oVkFdVMv8wH668xs4aT5wzks8APJF1K1vexBvhUVaOyymqWX+bt0l9j1iLyXAfyKHCopDcDiog/VT8sy6PlZtn1SCqzppJnTfTRwEeBScBIKRuAFRFuV6ij/ll2+68w759lF2jeJNJM/TVmlqsP5KfATOA14M8FN6ujlpxlt5n6a8wsVx/I+IioyrwXko4BvgWMAK6IiAsHPD8auBZ4D/Ac8LGIeCI9Nw84g2xY8dkRsaQaMTaqlp1lt1n6a8waWY2WYc6TQH4j6cCIWFnJA0saAVwGHAX0AvdKWhwRDxXsdgbwQkTsJ2k2cBHwMUn7A7OBdwHjgF9K+suI2PYneQsb19nB2iLJohlm2W25vhuzRlLDZZjzNGEdDiyTtErSCkkrJa2owLEPAVZHxGPpOpPryZrKCs0kWw0R4EbgSGWdMDOB6yPi1Yh4HFid3q9tzJkxlY5RI7Yp659ld9HytRx24e1MnnsLh114e0OtPljLFRIb+e9gVjU1HA6f5wzk2IofNdNFNiS4Xy/w3lL7RMRrkjaSLa3bBfx2wGuL/oSVdCZwJsDEiRMrEngj6P/FPvCXPNDQneuD9d1UMr6WHGRglkcNh8MPNhvvbhHxIlCtYbvF5tMaOOtvqX3yvDYrjLgcuBygu7u76D7Natb0ru2+DA+78PaafEGXq1Z9N7VKVGYNp4bD4Qdrwvphul8G9KT7ZQXbw9ULTCjYHg+sK7WPpJHAGOD5nK9tS43euV6rFRIb/e9gVjU1nFh0sNl4P5z6G94fEftGxOSC274VOPa9wBRJk9PcWrOBxQP2WQycmh6fBNweEZHKZ0saLWkyMAX4XQVianrV+IKuZF/CYH03ldRWS/maFarhcPhB+0AiIiTdRDaMtqJSn8ZZwBKyYbxXRcSDks4HeiJiMXAlcJ2k1WRnHrPTax+UtAB4iOz6lP/eTiOwBlPpJWyH3Jewg+GDpfpuKt2s1DZL+ZoVU6Ph8Mp+0A+yg3QZ8L2IuLfq0VRZd3d39PRUovWtsQ11mOxg+x924e1Fhwt3dXbw67lHbFs4cPggZKfOdboY0MOFzSpD0rKI6N6uPEcCeQiYCjxBdgW6yE5Omm5J23ZJIEMx8AwDsl/qF5x4ILOmdzF57i1FRycIePzCD21bePEBJTrvJsDnH6ho3Ga1uljOSieQeg7jtQawo9FKQ7pg0bPpWq3U8GI5K61kJ7qkXST9AzAHOAZY27+sbVra1lrAjkYrDanTu86rH/rCwTbitWMawmDDeK8BuoGVZGch/1KTiGx4hrgk7I5GK82a3sUFJx5IV2cHIuv76G/e2k691iVfsYCXL3oHJyx6Fze8/Hccv9OvqnqFuzUAn+02hMGasPaPiAMBJF2Jh8k2vjJO6/OMVip2wWJR/ceoZbt0qvOum/tAMF7PcuGoK2AzLN58uC8cbFVeO6YhDJZANvc/SENuaxCODctgp/UlvsQrPqy2isMHi46qunP7Ou+qTXxx5AIWbzrcFw62Kq8d0xAGSyB/JenF9FhAR9ruH4W1W9Wjs6Ep87Q+9xlGHZW6HmXmiN6i89qM03PZfYUvHCw5NNgjgmqrHme7tp2SCSQiRpR6zhpUC5/Wlxot9vSIvXgb67fbf13sWfELB0slsa41P+Pgled6RFCtee2Yussznbs1i3p1YlfZouVriw4lBrhg08nb1fnl2Jkrdv5k6c7+MpVKYhPum+8RQdaW8lwHYtVQjSaPFjyt7//VX0rPbkfBcdO3qfOuR57DeVWoc6n+lL1jffH5oT0iyFqcE0helfzCr+ZFUC12Wl/sV3+/rU1U046oSZ1LXVT5jMYWbUZrhaZDs8G4CSuP/i/8jWuAeOMLfwfXWJTki6ByG2wUVaWbqHak1EWVaw6a05JNh2Y74jOQPMoYHjuoNrgIqlITGZb61d/V2VHzkWOlhjwfPP0YmLR7WWeonvDRmpkTSB6V/sJv4dFSkGMK+CE0BzbatOwlhzyX0XToZXet2bkJK49Kz/HUoqOl+g02QeNQmwOHNJVKkxn072TWBHwGkkelr3ptwdFShQadoLHMq+VbIWEM5GV3rdk5geRRjS/8FhstVWjQKeDboP8nryFNlW/WgJxA8mrQL/xG7IQdtN/iztbu/xmKRuvfMRsqJ5Am1qidsINO0DjCk+D1q9X68GbVssMlbVtJqy1pO6T1yhuJJx40ayrDWdLWGlSp+aEavhO2QZsDzWxoPIy3SS1avrbo9EvgTlgzqw0nkCY1f8kqijU+CtwJa2Y14SasJlWqmSqoXwd6PUeENeJoNLNWV5czEEl7SLpN0iPpfvcS+52a9nlE0qmpbFdJt0j6g6QHJV1Y2+hzWLEALj4AzuvM7suddHEQpZqpuurUfNU/Imzthj6CN0aELVq+tqWPbdbO6tWENRdYGhFTgKVpexuS9gDOBd4LHAKcW5Bovh4R7wCmA4dJOrY2YedQ6Zl7Syg1M2y9mq/qOS2HpwQxq496JZCZwDXp8TXArCL7zABui4jnI+IF4DbgmIh4OSLuAIiITcB9QONchVajqdobbY6oek7L4SlBzOqjXn0gb42IpwAi4ilJexfZpwsovGS5N5VtJakTOB74VqkDSToTOBNg4sSJwww7hxpO1dFIc0TVc1oOTwliVh9VOwOR9EtJDxS5zcz7FkXKtg48kjQS+BFwSUQ8VupNIuLyiOiOiO6xY8cOrRLlqPTMvU2ink1qjdacZ9YuqnYGEhEfLPWcpKcl7ZPOPvYBnimyWy/wgYLt8cCdBduXA49ExDcrEG7lVHrm3jwa4Mruek7L4SlBzOqjLlOZSJoPPBcRF0qaC+wREV8csM8ewDLgoFR0H/CeiHhe0v8C3gmcHBGv5z1uzaYyqeUX+sD11SFLWMdf4qu9zawiSk1lUq8EsiewAJgI/JEsETwvqRv4bER8Ju13OvCl9LJ/joirJY0n6xv5A/Bqeu7SiLhiR8dttbmwgGyYcNHZbSfA5x+ofTxm1nIaai6siHgOOLJIeQ/wmYLtq4CrBuzTS/H+kfbk9TXMrE48lUmza9NOezOrPyeQZlfJ9dVrcAV9TbRKPcwanOfCanaVWm53YGd8/xX0hcdoBq1SD7Mm4AWlLNMqnfGtUg+zBlKqE91NWJZplc74VqmHWRNwArFMq3TGt0o9zJqAE4hlKtkZX0+tUg+zJuAEYplpp2RXr4+ZACi7b8ar2VulHmZNwJ3oZmY2KHeim5lZRTmBmJlZWZxAzMysLE4gZmZWFicQMzMrixOImZmVxQnEzMzK4gRiZmZlcQIxM7OyOIGYmVlZnEDMzKwsTiBmZlYWJxAzMyuLE4iZmZXFCcTMzMriBGJmZmVxAjEzs7K01YqEktYDT9Y7jhz2Ap6tdxA11G71hfarc7vVF1qrzm+PiLEDC9sqgTQLST3Flo9sVe1WX2i/OrdbfaE96uwmLDMzK4sTiJmZlcUJpDFdXu8Aaqzd6gvtV+d2qy+0QZ3dB2JmZmXxGYiZmZXFCcTMzMriBFJjkk6W9KCk1yV1D3hunqTVklZJmlFQfkwqWy1pbkH5ZEn3SHpE0g2Sdq5lXSqhVN2ajaSrJD0j6YGCsj0k3Zb+fW6TtHsql6RLUp1XSDqo4DWnpv0fkXRqPeqSh6QJku6Q9HD6//y5VN7Kdd5F0u8k/T7V+aupvOjnUNLotL06PT+p4L2KftabTkT4VsMb8E5gKnAn0F1Qvj/we2A0MBl4FBiRbo8C+wI7p332T69ZAMxOj78N/Nd612+If4uSdWu2G/A3wEHAAwVlXwPmpsdzgYvS4+OAXwACDgXuSeV7AI+l+93T493rXbcS9d0HOCg9fgvwf9P/4Vaus4A3p8ejgHtSXYp+DoH/Bnw7PZ4N3JAeF/2s17t+5dx8BlJjEfFwRKwq8tRM4PqIeDUiHgdWA4ek2+qIeCwiNgHXAzMlCTgCuDG9/hpgVvVrUFFF61bnmMoSEXcBzw8onkn27wLb/vvMBK6NzG+BTkn7ADOA2yLi+Yh4AbgNOKb60Q9dRDwVEfelx38CHga6aO06R0S8lDZHpVtQ+nNY+Le4ETgyfW5LfdabjhNI4+gC1hRs96ayUuV7Ahsi4rUB5c2kVN1axVsj4inIvnCBvVP5UP+tG1pqmplO9ou8pessaYSk+4FnyJLdo5T+HG6tW3p+I9nntqnqPJiR9Q6gFUn6JfC2Ik99OSJ+WuplRcqC4kk+Btm/mbRCHcpRqt5N9/eQ9GbgJ8A/RMSL2Q/s4rsWKWu6OkfEFuDdkjqBm8iapLfbLd23RJ0H4wRSBRHxwTJe1gtMKNgeD6xLj4uVP0vWDDAy/bop3L9ZDFbnVvC0pH0i4qnUXPNMKi9V717gAwPK76xBnGWRNIosefwgIham4pauc7+I2CDpTrI+kFKfw/4690oaCYwha+Zsmf/3bsJqHIuB2WnkxmRgCvA74F5gShrpsTNZZ9ziyHrj7gBOSq8/FSh1dtOoitatzjFV0mKyfxfY9t9nMfCpNDLpUGBjau5ZAhwtafc0eunoVNZwUlv+lcDDEfGNgqdauc5j05kHkjqAD5L1/ZT6HBb+LU4Cbk+f21Kf9eZT7178drsBHyH7BfIq8DSwpOC5L5O1qa4Cji0oP45slMujZM1g/eX7kv3HWw38GBhd7/qV8fcoWrdmuwE/Ap4CNqd/3zPI2ruXAo+k+z3SvgIuS3Veybaj8U5P/56rgU/Xu16D1PdwsmaXFcD96XZci9d5GrA81fkB4JxUXvRzCOyStlen5/cteK+in/Vmu3kqEzMzK4ubsMzMrCxOIGZmVhYnEDMzK4sTiJmZlcUJxMzMyuIEYk1D0hZJ90t6QNKPJe1aYr+f94/XH+L7j5N04473LPn6JyTtVe7rm4Wk0ySNK/FcydmmrfU4gVgz6YuId0fEAcAm4LOFT6aL1HaKiOMiYsNQ3zwi1kXESTves+2dBhRNIGTXR5wI3FWzaKxunECsWf0fYD9Jk9KaFP8G3AdM6D8TKHjuu+lX8b+nK4iRtJ+kX6a1He6T9Bdp/wfS86dJ+qmkW9OaDef2H1jSIknL0nueuaNAlWwwfi0AAANLSURBVK15cl861tJUtkd6nxWSfitpWio/T9I1KdYnJJ0o6WuSVqZYRqX9npB0kbL1KX4nab9U/nZJS9P7LpU0MZV/T9l6HL+R9JikkwrimyPp3vSa/jUuiv7t0uu6gR+ks8GOwrpG6dmmrQU5gVjTSfMKHUt2RTNk66tcGxHTI+LJAbtPAS6LiHcBG4CPpvIfpPK/Av6a7CrygQ4BPgG8Gzi5oEnm9Ih4D9kX6dmS9hwk1rHAd4GPpmOdnJ76KrA8IqYBXwKuLXjZXwAfIpv2+/vAHRFxINCXyvu9GBGHAJcC30xll6a/xbRUx0sK9t+H7AryDwMXpviOTn+jQ1I93yPpb0r97SLiRqAH+EQ6G+wrVXdrfU4g1kw6lE2l3QP8kWwuJoAnI1tjopjHI+L+9HgZMEnSW4CuiLgJICJeiYiXi7z2toh4Ln1JLiT78oUsafwe+C3ZpHhTBon5UOCuyNZ9ICL61ww5HLguld0O7ClpTHruFxGxmSxBjgBuTeUrgUkF7/2jgvv3pcfvA36YHl9XEDPAooh4PSIeAt6ayo5Ot+VkZ3DvKKjPdn+7Qeppbciz8Voz6YuIdxcWZHP68edBXvNqweMtQAfFp9MuZuA8PyHpA2ST6L0vIl5WNiPrLoO8h4q8T395qeO9ChARr0vaHG/MN/Q6235mo8TjYu+59X0HHF/ABRHxnW2Cy9b4KPa3M9vKZyDWdiLiRbIptmfB1rWri43oOir1VXSQrTL3a7IpuV9IyeMdZGcYg7kbeH+adRVJe6Tyu8iax0hJ6dkU11B8rOD+7vT4N2SzGpPe/1c7eI8lwOnK1vVAUpekvXfwmj+RLWNrbc5nINau/gvwHUnnk82gezLZL/xCvyJrBtoP+GFE9EhaCXxW0gqymVRLNZ0BEBHrU0f7Qkk7ka2PcRRwHnB1ep+XeWPa76EYLekesh+CH09lZwNXSZoDrAc+vYP4/l3SO4G709ncS8Anyc44Svke8G1JfWRnYlv7QSR9BPhXYCxwi6T7I2JGGXWzJuDZeM2KkHQa2ZTjZ9U7lmIkPUEW37P1jsXal5uwzMysLD4DMTOzsvgMxMzMyuIEYmZmZXECMTOzsjiBmJlZWZxAzMysLP8flJZM3sLPh0sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Visualization(file_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = our_train_and_split(target,file_vectors,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 9, 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 3, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    0.733333   \n",
       "1                           svm    0.666667   \n",
       "2                 random_forest    0.700000   \n",
       "3                           knn    0.700000   \n",
       "4                 decision_tree    0.600000   \n",
       "5         bagged_decision_trees    0.733333   \n",
       "6  stochastic_gradient_boosting    0.766667   \n",
       "7                           sgd    0.500000   \n",
       "8                   naive_bayes    0.500000   \n",
       "\n",
       "                                         best_params  \n",
       "0                        {'C': 100, 'penalty': 'l2'}  \n",
       "1  {'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...  \n",
       "2      {'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "3  {'metric': 'euclidean', 'n_neighbors': 9, 'wei...  \n",
       "4         {'max_depth': 10, 'min_samples_split': 15}  \n",
       "5                              {'n_estimators': 100}  \n",
       "6  {'learning_rate': 0.001, 'max_depth': 3, 'n_es...  \n",
       "7                                  {'penalty': 'l1'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(x_train, y_train, x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df[\"best_params\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 9, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 13, 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 3, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 1.0\n",
      "Recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(x_train, y_train, x_test, y_test, 'log2', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling only lengh file prameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_lst = [v[-1] for v in file_vectors]\n",
    "max_len = max(len_lst)\n",
    "min_len = min(len_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_len_x_train= [v[:-1] for v in x_train]\n",
    "without_len_x_test= [v[:-1] for v in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_len_only_x_train=[]\n",
    "for i,v in enumerate(without_len_x_train):\n",
    "    temp= v\n",
    "    temp.append((x_train[i][-1]-min_len)/(max_len-min_len))\n",
    "    scale_len_only_x_train.append(temp)\n",
    "    \n",
    "scale_len_only_x_test=[]    \n",
    "for i,v in enumerate(without_len_x_test):\n",
    "    temp= v\n",
    "    temp.append((x_test[i][-1]-min_len)/(max_len-min_len))\n",
    "    scale_len_only_x_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 13, 'we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    0.733333   \n",
       "1                           svm    0.733333   \n",
       "2                 random_forest    0.633333   \n",
       "3                           knn    0.733333   \n",
       "4                 decision_tree    0.600000   \n",
       "5         bagged_decision_trees    0.600000   \n",
       "6  stochastic_gradient_boosting    0.766667   \n",
       "7                           sgd    0.666667   \n",
       "8                   naive_bayes    0.666667   \n",
       "\n",
       "                                         best_params  \n",
       "0                         {'C': 10, 'penalty': 'l2'}  \n",
       "1  {'C': 0.001, 'gamma': 'scale', 'kernel': 'sigm...  \n",
       "2     {'max_features': 'sqrt', 'n_estimators': 1000}  \n",
       "3  {'metric': 'manhattan', 'n_neighbors': 13, 'we...  \n",
       "4          {'max_depth': 15, 'min_samples_split': 3}  \n",
       "5                               {'n_estimators': 10}  \n",
       "6  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...  \n",
       "7                                  {'penalty': 'l1'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(scale_len_only_x_train, y_train, scale_len_only_x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df[\"best_params\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(scale_len_only_x_train, y_train, scale_len_only_x_test, y_test,'sqrt', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.8\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(scale_len_only_x_train, y_train, scale_len_only_x_test, y_test,'log2', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "SVM_Classifier(scale_len_only_x_train, y_train, scale_len_only_x_test, y_test, 'sigmoid', 0.001, 'scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'manhattan', 13, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scaling our vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41429256, 0.3438831 , 0.19294157, 0.40585477, 0.78022516,\n",
       "       0.57898049, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.06354007, 0.59939654, 0.        , 0.19823789, 0.24874135,\n",
       "       0.46449754, 0.60707688, 0.33012115, 0.34471366, 0.        ,\n",
       "       0.68888889, 0.        , 0.67241379, 0.        , 0.37037037,\n",
       "       0.01869531])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tring scaling our vectors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_file_vectors = scaler.fit(file_vectors).transform(file_vectors)\n",
    "scale_file_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Visualization(scale_file_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "scale_x_train, y_train, scale_x_test, y_test = our_train_and_split(target,file_vectors,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 21, 'we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    0.700000   \n",
       "1                           svm    0.633333   \n",
       "2                 random_forest    0.666667   \n",
       "3                           knn    0.700000   \n",
       "4                 decision_tree    0.500000   \n",
       "5         bagged_decision_trees    0.600000   \n",
       "6  stochastic_gradient_boosting    0.700000   \n",
       "7                           sgd    0.500000   \n",
       "8                   naive_bayes    0.500000   \n",
       "\n",
       "                                         best_params  \n",
       "0                        {'C': 100, 'penalty': 'l2'}  \n",
       "1   {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}  \n",
       "2      {'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "3  {'metric': 'euclidean', 'n_neighbors': 21, 'we...  \n",
       "4          {'max_depth': 3, 'min_samples_split': 21}  \n",
       "5                               {'n_estimators': 10}  \n",
       "6  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...  \n",
       "7                                  {'penalty': 'l1'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(scale_x_train, y_train, scale_x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 21, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df[\"best_params\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(x_train, y_train, x_test, y_test, 'log2', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 3, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Precision: 0.75\n",
      "Recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "SVM_Classifier(scale_x_train, y_train, scale_x_test, y_test, 'rbf', 0.7, 'scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vectors didn't include the file length parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vectors_without_len = [vec[:-1] for vec in file_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Visualization(file_vectors_without_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "x_train_without_len_param, y_train, x_test_without_len_param, y_test = our_train_and_split(target, file_vectors_without_len, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_without_len_param = [vec[:-1] for vec in x_train]\n",
    "x_test_without_len_param = [vec[:-1] for vec in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liat\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 21, 'we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bagged_decision_trees</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>stochastic_gradient_boosting</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 7, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  best_score  \\\n",
       "0           logistic_regression    0.700000   \n",
       "1                           svm    0.633333   \n",
       "2                 random_forest    0.666667   \n",
       "3                           knn    0.700000   \n",
       "4                 decision_tree    0.500000   \n",
       "5         bagged_decision_trees    0.633333   \n",
       "6  stochastic_gradient_boosting    0.700000   \n",
       "7                           sgd    0.500000   \n",
       "8                   naive_bayes    0.500000   \n",
       "\n",
       "                                         best_params  \n",
       "0                        {'C': 100, 'penalty': 'l2'}  \n",
       "1   {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}  \n",
       "2      {'max_features': 'log2', 'n_estimators': 100}  \n",
       "3  {'metric': 'euclidean', 'n_neighbors': 21, 'we...  \n",
       "4          {'max_depth': 3, 'min_samples_split': 21}  \n",
       "5                             {'n_estimators': 1000}  \n",
       "6  {'learning_rate': 0.01, 'max_depth': 7, 'n_est...  \n",
       "7                                  {'penalty': 'l1'}  \n",
       "8                                                 {}  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = GridSearchCV_TrainSetResult(scale_x_train, y_train, scale_x_test, y_test, 5)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Precision: 0.625\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "RANDOMFFOREST_Classifier(x_train_without_len_param, y_train, x_test_without_len_param, y_test, 'sqrt', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "SVM_Classifier(x_train_without_len_param, y_train, x_test_without_len_param, y_test, 'poly', 0.1, 'scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "KNN_Classifier(x_train, y_train, x_test, y_test, 'euclidean', 3, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
